{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42ed2896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Aula Prática – Integração entre PostgreSQL (Pagila) e APIs com Python\n",
    "\n",
    "# Nesta atividade, você irá:\n",
    "# - Consultar dados da base Pagila com `psycopg2`\n",
    "# - Integrar dados climáticos e populacionais usando APIs externas\n",
    "# - Analisar, transformar e visualizar os dados\n",
    "# - Praticar o uso de Pandas, APIs, SQL e operações avançadas como `lambda`, `groupby`, `merge`, entre outras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c8a1bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports e Configurações Iniciais\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import requests\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "from tabulate import tabulate\n",
    "import numpy as np # Adicionado para simulações e operações numéricas\n",
    "import time # Para throttling opcional de API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "531f9372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL version: PostgreSQL 16.8 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 14.2.1 20240912 (Red Hat 14.2.1-3), 64-bit\n"
     ]
    }
   ],
   "source": [
    "# Carregar variáveis de ambiente do arquivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Obter as variáveis de ambiente para conexão com o banco\n",
    "db = os.getenv(\"PG_DB\")\n",
    "user = os.getenv(\"PG_USER\")\n",
    "password = os.getenv(\"PG_PASSWORD\")\n",
    "host = os.getenv(\"PG_HOST\")\n",
    "port = os.getenv(\"PG_PORT\")\n",
    "sslmode = os.getenv(\"PG_SSLMODE\")\n",
    "\n",
    "\n",
    "# Chaves de API (serão usadas pelas funções de busca)\n",
    "WEATHER_API_KEY = os.getenv(\"WEATHER_KEY\")\n",
    "AIRVISUAL_API_KEY = os.getenv(\"AIRVISUAL_KEY\")\n",
    "\n",
    "# Estabelecer conexão com o PostgreSQL\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=db, user=user, password=password, host=host, port=port, sslmode=sslmode\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT VERSION()\")\n",
    "    version = cur.fetchone()[0]\n",
    "    print(f\"PostgreSQL version: {version}\")\n",
    "    # cur.close() # Fechar o cursor aqui se não for mais usá-lo globalmente logo em seguida\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao conectar ao PostgreSQL: {e}\")\n",
    "    conn = None # Define conn como None se a conexão falhar\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "504623cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções de API (Originais e com Cache - Implementação do Exercício 10 será integrada aqui)\n",
    "def run_query(sql, db_conn=conn):\n",
    "    \"\"\"\n",
    "    Executes a SQL query on the provided database connection and returns the result as a DataFrame.\n",
    "    \"\"\"\n",
    "    if db_conn is None:\n",
    "        print(\"Conexão com o banco de dados não está disponível.\")\n",
    "        return pd.DataFrame() # Retorna DataFrame vazio\n",
    "    try:\n",
    "        return pd.read_sql_query(sql, db_conn)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao executar query: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c614a757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuração do Cache (para Exercício 10) ---\n",
    "CACHE_DIR = \"api_cache\"\n",
    "WEATHER_CACHE_FILE = os.path.join(CACHE_DIR, \"weather_cache.csv\")\n",
    "AQI_CACHE_FILE = os.path.join(CACHE_DIR, \"aqi_cache.csv\")\n",
    "COUNTRIES_CACHE_FILE = os.path.join(CACHE_DIR, \"countries_cache.csv\")\n",
    "\n",
    "if not os.path.exists(CACHE_DIR):\n",
    "    os.makedirs(CACHE_DIR)\n",
    "\n",
    "# --- Funções de Cache Genéricas ---\n",
    "def carregar_cache_csv(filepath, key_col, value_col):\n",
    "    if os.path.exists(filepath):\n",
    "        try:\n",
    "            df = pd.read_csv(filepath)\n",
    "            # Tratar NaNs que podem ser lidos como strings\n",
    "            df[value_col] = df[value_col].replace({'nan': np.nan, 'None': np.nan})\n",
    "            return df.set_index(key_col)[value_col].to_dict()\n",
    "        except pd.errors.EmptyDataError:\n",
    "            return {}\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao carregar cache de {filepath}: {e}\")\n",
    "            return {}\n",
    "    return {}\n",
    "\n",
    "def salvar_cache_csv(cache_data, filepath, key_name, value_name):\n",
    "    try:\n",
    "        pd.DataFrame(list(cache_data.items()), columns=[key_name, value_name]).to_csv(filepath, index=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao salvar cache em {filepath}: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da46b262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A temperatura atual em Brasília é de 19.0°C\n"
     ]
    }
   ],
   "source": [
    "def _buscar_clima_api(cidade): # Função \"privada\" que realmente chama a API\n",
    "    if not WEATHER_API_KEY:\n",
    "        # print(\"Chave da API WeatherAPI (WEATHER_KEY) não configurada.\")\n",
    "        return None\n",
    "    try:\n",
    "        url = f\"http://api.weatherapi.com/v1/current.json?key={WEATHER_API_KEY}&q={cidade}&aqi=no\"\n",
    "        resposta = requests.get(url, timeout=10)\n",
    "        resposta.raise_for_status()\n",
    "        dados = resposta.json()\n",
    "        if \"current\" in dados and \"temp_c\" in dados[\"current\"]:\n",
    "            return dados[\"current\"][\"temp_c\"]\n",
    "        else:\n",
    "            # print(f\"Dados de temperatura não encontrados para {cidade} na resposta da API.\")\n",
    "            return None\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        # print(f\"Erro HTTP ao buscar clima para {cidade}: {http_err.response.status_code}\")\n",
    "        return None\n",
    "    except requests.exceptions.RequestException: # Outros erros de request\n",
    "        # print(f\"Erro na requisição ao buscar clima para {cidade}: {req_err}\")\n",
    "        return None\n",
    "    except Exception: # Erro genérico (ex: parsing JSON)\n",
    "        # print(f\"Erro inesperado ao buscar clima para {cidade}: {e}\")\n",
    "        return None\n",
    "# --- Cache para WeatherAPI ---\n",
    "weather_cache = carregar_cache_csv(WEATHER_CACHE_FILE, 'city_query', 'temperatura')\n",
    "\n",
    "def buscar_clima(cidade): # Função pública que usa o cache\n",
    "    global weather_cache\n",
    "    if pd.isna(cidade) or cidade == \"\":\n",
    "        return None\n",
    "    cidade_query_key = str(cidade).lower()\n",
    "\n",
    "    if cidade_query_key in weather_cache:\n",
    "        cached_value = weather_cache[cidade_query_key]\n",
    "        if not pd.isna(cached_value): # Só retorna se não for NaN explicitamente cacheado\n",
    "            # print(f\"CACHE HIT (Clima): {cidade}\")\n",
    "            return float(cached_value)\n",
    "        # Se for NaN cacheado, significa que já tentamos e falhou, então não tentamos de novo (a menos que a lógica mude)\n",
    "\n",
    "    # print(f\"API CALL (Clima): {cidade}\")\n",
    "    time.sleep(0.1) # Pequeno delay para não sobrecarregar API\n",
    "    temperatura = _buscar_clima_api(cidade)\n",
    "    \n",
    "    weather_cache[cidade_query_key] = float(temperatura) if temperatura is not None else np.nan\n",
    "    salvar_cache_csv(weather_cache, WEATHER_CACHE_FILE, 'city_query', 'temperatura')\n",
    "    return temperatura\n",
    "\n",
    "# Exemplo de teste\n",
    "cidade = \"Brasília\"\n",
    "print(f\"A temperatura atual em {cidade} é de {buscar_clima(cidade)}°C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "992641d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O AQI atual em são paulo, sao paulo, Brazil é de 69.0\n"
     ]
    }
   ],
   "source": [
    "# --- Cache para AirVisual API ---\n",
    "aqi_cache = carregar_cache_csv(AQI_CACHE_FILE, 'location_query', 'aqi')\n",
    "\n",
    "def _buscar_aqi_cidade_api(cidade, estado, pais):\n",
    "    if not AIRVISUAL_API_KEY:\n",
    "        # print(\"Chave da API AirVisual (AIRVISUAL_KEY) não configurada.\")\n",
    "        return None\n",
    "    try:\n",
    "        # Tentar normalizar nomes para a API AirVisual, especialmente país\n",
    "        pais_api = pais # Pode precisar de mapeamento mais robusto (ver Ex4)\n",
    "        \n",
    "        url = f\"http://api.airvisual.com/v2/city?city={requests.utils.quote(cidade)}&state={requests.utils.quote(estado)}&country={requests.utils.quote(pais_api)}&key={AIRVISUAL_API_KEY}\"\n",
    "        resposta = requests.get(url, timeout=15)\n",
    "        resposta.raise_for_status()\n",
    "        dados = resposta.json()\n",
    "        if dados.get(\"status\") == \"success\" and dados.get(\"data\", {}).get(\"current\", {}).get(\"pollution\"):\n",
    "            return dados[\"data\"][\"current\"][\"pollution\"][\"aqius\"]\n",
    "        else:\n",
    "            # print(f\"Dados de AQI não encontrados para {cidade}, {estado}, {pais_api}. Status: {dados.get('status')}, Msg: {dados.get('data', {}).get('message')}\")\n",
    "            return None\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        # print(f\"Erro HTTP ao buscar AQI para {cidade}, {estado}, {pais}: {http_err.response.status_code}\")\n",
    "        return None\n",
    "    except requests.exceptions.RequestException:\n",
    "        # print(f\"Erro na requisição ao buscar AQI para {cidade}, {estado}, {pais}: {req_err}\")\n",
    "        return None\n",
    "    except Exception:\n",
    "        # print(f\"Erro inesperado ao buscar AQI para {cidade}, {estado}, {pais}: {e}\")\n",
    "        return None\n",
    "    \n",
    "def buscar_aqi_cidade(cidade, estado, pais):\n",
    "    global aqi_cache\n",
    "    if pd.isna(cidade) or pd.isna(estado) or pd.isna(pais) or \"\" in [cidade, estado, pais]:\n",
    "        return None\n",
    "        \n",
    "    location_query_key = f\"{str(cidade).lower()}|{str(estado).lower()}|{str(pais).lower()}\"\n",
    "\n",
    "    if location_query_key in aqi_cache:\n",
    "        cached_value = aqi_cache[location_query_key]\n",
    "        if not pd.isna(cached_value):\n",
    "            # print(f\"CACHE HIT (AQI): {location_query_key.replace('|',', ')}\")\n",
    "            return float(cached_value)\n",
    "\n",
    "    # print(f\"API CALL (AQI): {cidade}, {estado}, {pais}\")\n",
    "    time.sleep(0.2) # AirVisual pode ser mais sensível a rate limits\n",
    "    aqi = _buscar_aqi_cidade_api(cidade, estado, pais)\n",
    "    \n",
    "    aqi_cache[location_query_key] = float(aqi) if aqi is not None else np.nan\n",
    "    salvar_cache_csv(aqi_cache, AQI_CACHE_FILE, 'location_query', 'aqi')\n",
    "    return aqi\n",
    "\n",
    "# Exemplo de teste\n",
    "cidade = \"são paulo\"\n",
    "estado = \"sao paulo\"\n",
    "pais = \"Brazil\"\n",
    "print(f\"O AQI atual em {cidade}, {estado}, {pais} é de {buscar_aqi_cidade(cidade, estado, pais)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bae7f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cache para REST Countries API ---\n",
    "\n",
    "# Para countries_cache, o valor é um dicionário, então o tratamento é um pouco diferente.\n",
    "def carregar_cache_paises():\n",
    "    if os.path.exists(COUNTRIES_CACHE_FILE):\n",
    "        try:\n",
    "            df = pd.read_csv(COUNTRIES_CACHE_FILE)\n",
    "            cache = {}\n",
    "            for _, row in df.iterrows():\n",
    "                country_key = row['country_query']\n",
    "                data_val = row['data']\n",
    "                if pd.notna(data_val) and str(data_val).lower() not in ['nan', 'none']:\n",
    "                    try:\n",
    "                        cache[country_key] = eval(data_val) # eval pode ser arriscado; use json.loads se o dado for JSON string\n",
    "                    except: # se eval falhar\n",
    "                        cache[country_key] = None # ou algum marcador de erro\n",
    "                else:\n",
    "                    cache[country_key] = None # Representa um None/NaN que foi explicitamente cacheado\n",
    "            return cache\n",
    "        except pd.errors.EmptyDataError: return {}\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao carregar cache de países: {e}\")\n",
    "            return {}\n",
    "    return {}\n",
    "\n",
    "\n",
    "def salvar_cache_paises(cache_data):\n",
    "    try:\n",
    "        df_list = []\n",
    "        for key, value in cache_data.items():\n",
    "            df_list.append({'country_query': key, 'data': str(value) if value is not None else None}) # Salvar como string\n",
    "        pd.DataFrame(df_list).to_csv(COUNTRIES_CACHE_FILE, index=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao salvar cache de países: {e}\")\n",
    "\n",
    "\n",
    "paises_cache = carregar_cache_paises()\n",
    "\n",
    "# Mapeamento de nomes de países (Pagila -> API RESTCountries)\n",
    "country_name_map_rest = {\n",
    "    \"United States\": \"United States of America\",\n",
    "    \"Iran (Islamic Republic of)\": \"Iran\",\n",
    "    \"Russian Federation\": \"Russia\",\n",
    "    \"Czech Republic\": \"Czechia\",\n",
    "    \"Korea (South)\": \"South Korea\", \"Korea, Republic of\": \"South Korea\",\n",
    "    \"Macedonia\": \"North Macedonia\",\n",
    "    \"Taiwan\": \"Taiwan\",\n",
    "    \"Viet Nam\": \"Vietnam\",\n",
    "    \"Congo (Dem. Rep.)\": \"Democratic Republic of the Congo\", \"Congo, The Democratic Republic of the\": \"Democratic Republic of the Congo\",\n",
    "    \"Holy See (Vatican City State)\": \"Vatican City\",\n",
    "    \"RUNION\": \"Réunion\", # Pagila parece ter \"RUNION\" para \"Réunion\"\n",
    "    \"Brasil\": \"Brazil\", # Adicionado para evitar problemas de mapeamento\n",
    "}\n",
    "\n",
    "def _buscar_dados_pais_api(nome_pais_api):\n",
    "    try:\n",
    "        url = f\"https://restcountries.com/v3.1/name/{requests.utils.quote(nome_pais_api)}?fullText=false\"\n",
    "        resposta = requests.get(url, timeout=10)\n",
    "        resposta.raise_for_status()\n",
    "        dados_pais_lista = resposta.json()\n",
    "        \n",
    "        if dados_pais_lista:\n",
    "            # Tentar encontrar o melhor match ou pegar o primeiro com os dados esperados\n",
    "            for pais_info in dados_pais_lista:\n",
    "                if 'population' in pais_info and 'name' in pais_info:\n",
    "                    return {\n",
    "                        'name_common': pais_info['name'].get('common', nome_pais_api),\n",
    "                        'name_official': pais_info['name'].get('official', nome_pais_api),\n",
    "                        'population': pais_info.get('population'),\n",
    "                        'region': pais_info.get('region'), # Continente\n",
    "                        'subregion': pais_info.get('subregion')\n",
    "                    }\n",
    "            # Fallback se não encontrar um match ideal, mas ainda tiver dados\n",
    "            if dados_pais_lista[0]:\n",
    "                return {\n",
    "                    'name_common': dados_pais_lista[0]['name'].get('common', nome_pais_api),\n",
    "                    'name_official': dados_pais_lista[0]['name'].get('official', nome_pais_api),\n",
    "                    'population': dados_pais_lista[0].get('population'),\n",
    "                    'region': dados_pais_lista[0].get('region'),\n",
    "                    'subregion': dados_pais_lista[0].get('subregion')\n",
    "                }\n",
    "        # print(f\"Dados não encontrados ou incompletos para o país na API: {nome_pais_api}\")\n",
    "        return None\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        # if http_err.response.status_code == 404:\n",
    "            # print(f\"País não encontrado na API REST Countries: {nome_pais_api}\")\n",
    "        # else:\n",
    "            # print(f\"Erro HTTP ao buscar dados para {nome_pais_api}: {http_err.response.status_code}\")\n",
    "        return None\n",
    "    except requests.exceptions.RequestException: # Outros erros de request\n",
    "        # print(f\"Erro na requisição ao buscar dados para {nome_pais_api}: {req_err}\")\n",
    "        return None\n",
    "    except Exception: # Erro genérico\n",
    "        # print(f\"Erro inesperado ao buscar dados para {nome_pais_api}: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "def buscar_dados_pais(nome_pais_pagila):\n",
    "    global paises_cache\n",
    "    if pd.isna(nome_pais_pagila) or nome_pais_pagila == \"\":\n",
    "        return None\n",
    "\n",
    "    nome_pais_query_key = str(nome_pais_pagila).lower()\n",
    "    nome_pais_api = country_name_map_rest.get(nome_pais_pagila, nome_pais_pagila) # Usar nome mapeado se existir\n",
    "\n",
    "    if nome_pais_query_key in paises_cache:\n",
    "        cached_value = paises_cache[nome_pais_query_key]\n",
    "        if cached_value is not None: # Se não for o None explicitamente cacheado\n",
    "            # print(f\"CACHE HIT (País): {nome_pais_pagila} -> {nome_pais_api}\")\n",
    "            return cached_value\n",
    "        # Se for None cacheado, já tentamos e falhou\n",
    "\n",
    "    # print(f\"API CALL (País): {nome_pais_pagila} -> {nome_pais_api}\")\n",
    "    time.sleep(0.1)\n",
    "    dados = _buscar_dados_pais_api(nome_pais_api)\n",
    "    \n",
    "    paises_cache[nome_pais_query_key] = dados # Cacheia o dicionário ou None\n",
    "    salvar_cache_paises(paises_cache)\n",
    "    return dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02c2b15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Exercício 1: Temperatura Média das Cidades dos Clientes ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dgeis\\AppData\\Local\\Temp\\ipykernel_19340\\720489529.py:10: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql_query(sql, db_conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando clima para 20 cidades (Ex1)...\n",
      "\n",
      "Cidades (filtradas por >10 transações totais) com suas temperaturas e número de clientes (amostra):\n",
      "+----+-------------+----------------+---------------------------+---------------+\n",
      "|    | city        |   num_clientes |   total_transacoes_cidade |   temperatura |\n",
      "|----+-------------+----------------+---------------------------+---------------|\n",
      "|  0 | London      |              2 |                        48 |           8.1 |\n",
      "|  1 | Aurora      |              2 |                        50 |          13.7 |\n",
      "|  2 | Springs     |              2 |                        58 |           8.2 |\n",
      "|  3 | Acua        |              1 |                        26 |          23.6 |\n",
      "|  4 | Adana       |              1 |                        26 |          19.2 |\n",
      "|  5 | Addis Abeba |              1 |                        23 |          18.3 |\n",
      "|  6 | Aden        |              1 |                        31 |          29.2 |\n",
      "|  7 | Adoni       |              1 |                        22 |          26.8 |\n",
      "|  8 | Ahmadnagar  |              1 |                        33 |          26.2 |\n",
      "|  9 | Akishima    |              1 |                        28 |          25.4 |\n",
      "+----+-------------+----------------+---------------------------+---------------+\n",
      "\n",
      "Temperatura média ponderada (POR NÚMERO DE CLIENTES) das cidades amostradas: 19.55°C\n",
      "\n",
      "Cidades (amostra) com temperaturas mais altas (e seus clientes):\n",
      "+----+-----------------------+----------------+---------------+\n",
      "|    | city                  |   num_clientes |   temperatura |\n",
      "|----+-----------------------+----------------+---------------|\n",
      "| 15 | Allende               |              1 |          34.5 |\n",
      "| 16 | al-Manama             |              1 |          32.2 |\n",
      "| 18 | al-Qadarif            |              1 |          31.5 |\n",
      "|  6 | Aden                  |              1 |          29.2 |\n",
      "|  7 | Adoni                 |              1 |          26.8 |\n",
      "| 11 | al-Ayn                |              1 |          26.5 |\n",
      "|  8 | Ahmadnagar            |              1 |          26.2 |\n",
      "|  9 | Akishima              |              1 |          25.4 |\n",
      "| 14 | Allappuzha (Alleppey) |              1 |          24.1 |\n",
      "|  3 | Acua                  |              1 |          23.6 |\n",
      "+----+-----------------------+----------------+---------------+\n",
      "\n",
      "Cidades (amostra) com temperaturas mais baixas (e seus clientes):\n",
      "+----+-----------------+----------------+---------------+\n",
      "|    | city            |   num_clientes |   temperatura |\n",
      "|----+-----------------+----------------+---------------|\n",
      "|  0 | London          |              2 |           8.1 |\n",
      "|  2 | Springs         |              2 |           8.2 |\n",
      "| 10 | Akron           |              1 |          11.7 |\n",
      "| 17 | Almirante Brown |              1 |          12.4 |\n",
      "|  1 | Aurora          |              2 |          13.7 |\n",
      "| 12 | Alessandria     |              1 |          14.1 |\n",
      "| 13 | al-Hawiya       |              1 |          15.6 |\n",
      "|  5 | Addis Abeba     |              1 |          18.3 |\n",
      "| 19 | al-Qatif        |              1 |          18.3 |\n",
      "|  4 | Adana           |              1 |          19.2 |\n",
      "+----+-----------------+----------------+---------------+\n",
      "\n",
      "Cidades (amostra) com mais clientes (e suas temperaturas):\n",
      "+----+-------------+----------------+---------------+\n",
      "|    | city        |   num_clientes |   temperatura |\n",
      "|----+-------------+----------------+---------------|\n",
      "|  0 | London      |              2 |           8.1 |\n",
      "|  1 | Aurora      |              2 |          13.7 |\n",
      "|  2 | Springs     |              2 |           8.2 |\n",
      "|  3 | Acua        |              1 |          23.6 |\n",
      "|  4 | Adana       |              1 |          19.2 |\n",
      "|  5 | Addis Abeba |              1 |          18.3 |\n",
      "|  6 | Aden        |              1 |          29.2 |\n",
      "|  7 | Adoni       |              1 |          26.8 |\n",
      "|  8 | Ahmadnagar  |              1 |          26.2 |\n",
      "|  9 | Akishima    |              1 |          25.4 |\n",
      "+----+-------------+----------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "# Exercício 1 – Temperatura Média das Cidades dos Clientes (Corrigido para ponderação por NÚMERO DE CLIENTES)\n",
    "\n",
    "print(\"\\n--- Exercício 1: Temperatura Média das Cidades dos Clientes ---\")\n",
    "\n",
    "# 1. Recupere as cidades com mais de 10 transações totais e o número de clientes nessas cidades.\n",
    "query_cidades_clientes_transacoes = \"\"\"\n",
    "SELECT\n",
    "    ci.city,\n",
    "    COUNT(DISTINCT c.customer_id) AS num_clientes,    -- Para a ponderação\n",
    "    COUNT(p.payment_id) AS total_transacoes_cidade -- Para o critério de seleção da cidade\n",
    "FROM city ci\n",
    "    JOIN address a ON ci.city_id = a.city_id\n",
    "    JOIN customer c ON a.address_id = c.address_id\n",
    "    LEFT JOIN payment p ON c.customer_id = p.customer_id\n",
    "GROUP BY ci.city\n",
    "HAVING COUNT(p.payment_id) > 10 -- Cidades com mais de 10 transações no total\n",
    "ORDER BY num_clientes DESC;     -- Ordenar por número de clientes para a amostra\n",
    "\"\"\"\n",
    "df_cidades_info = run_query(query_cidades_clientes_transacoes) # DataFrame com informações da cidade\n",
    "\n",
    "if not df_cidades_info.empty:\n",
    "    # 2. Use a WeatherAPI para buscar a temperatura atual de uma amostra dessas cidades.\n",
    "    # df_cidades_info já está ordenado por num_clientes DESC devido à query SQL.\n",
    "    amostra_cidades_ex1 = df_cidades_info.head(20).copy() # Pega as 20 cidades com mais clientes (que atendem ao critério de transações)\n",
    "\n",
    "    print(f\"Buscando clima para {len(amostra_cidades_ex1)} cidades (Ex1)...\")\n",
    "    amostra_cidades_ex1.loc[:, 'temperatura'] = amostra_cidades_ex1['city'].apply(buscar_clima)\n",
    "\n",
    "    # Remove cidades para as quais não foi possível obter temperatura e converte para numérico\n",
    "    df_analise_ex1 = amostra_cidades_ex1.dropna(subset=['temperatura']).copy()\n",
    "\n",
    "    if not df_analise_ex1.empty: # Checa se, após buscar clima e remover NaNs, ainda temos dados\n",
    "        df_analise_ex1.loc[:, 'temperatura'] = pd.to_numeric(df_analise_ex1['temperatura'], errors='coerce')\n",
    "        df_analise_ex1.dropna(subset=['temperatura'], inplace=True) # Remove se to_numeric resultou em NaNs\n",
    "\n",
    "        if not df_analise_ex1.empty: # Checa novamente após a conversão numérica\n",
    "            print(\"\\nCidades (filtradas por >10 transações totais) com suas temperaturas e número de clientes (amostra):\")\n",
    "            print(tabulate(df_analise_ex1[['city', 'num_clientes', 'total_transacoes_cidade', 'temperatura']].head(10), headers=\"keys\", tablefmt=\"psql\"))\n",
    "\n",
    "            # 3. Calcule a temperatura média ponderada por NÚMERO DE CLIENTES.\n",
    "            df_analise_ex1.loc[:, 'num_clientes'] = pd.to_numeric(df_analise_ex1['num_clientes'], errors='coerce')\n",
    "\n",
    "            # DataFrame para ponderação, garantindo que não há NaNs nas colunas relevantes\n",
    "            df_ponderacao = df_analise_ex1.dropna(subset=['num_clientes', 'temperatura'])\n",
    "\n",
    "            if not df_ponderacao.empty and df_ponderacao['num_clientes'].sum() > 0:\n",
    "                temp_media_ponderada = (df_ponderacao['temperatura'] * df_ponderacao['num_clientes']).sum() / df_ponderacao['num_clientes'].sum()\n",
    "                print(f\"\\nTemperatura média ponderada (POR NÚMERO DE CLIENTES) das cidades amostradas: {temp_media_ponderada:.2f}°C\")\n",
    "            else:\n",
    "                print(\"\\nNão foi possível calcular a temperatura média ponderada (soma de clientes é zero, ou dados de clientes/temperatura inválidos/ausentes na amostra).\")\n",
    "\n",
    "            # 4. Insight esperado: quais cidades concentram clientes e temperaturas extremas?\n",
    "            # df_analise_ex1 já contém num_clientes e temperatura para a amostra.\n",
    "            df_analise_ex1_sorted_temp = df_analise_ex1.sort_values(by='temperatura', ascending=False)\n",
    "            print(\"\\nCidades (amostra) com temperaturas mais altas (e seus clientes):\")\n",
    "            print(tabulate(df_analise_ex1_sorted_temp.head(10)[['city', 'num_clientes', 'temperatura']], headers=\"keys\", tablefmt=\"psql\"))\n",
    "\n",
    "            df_analise_ex1_sorted_temp_baixa = df_analise_ex1.sort_values(by='temperatura', ascending=True)\n",
    "            print(\"\\nCidades (amostra) com temperaturas mais baixas (e seus clientes):\")\n",
    "            print(tabulate(df_analise_ex1_sorted_temp_baixa.head(10)[['city', 'num_clientes', 'temperatura']], headers=\"keys\", tablefmt=\"psql\"))\n",
    "\n",
    "            # Cidades com mais clientes (já que a amostra foi tirada do topo da lista ordenada por num_clientes)\n",
    "            print(\"\\nCidades (amostra) com mais clientes (e suas temperaturas):\")\n",
    "            print(tabulate(df_analise_ex1.head(10)[['city', 'num_clientes', 'temperatura']], headers=\"keys\", tablefmt=\"psql\"))\n",
    "        else:\n",
    "            print(\"A amostra de cidades ficou vazia após a tentativa de obter e converter temperaturas.\")\n",
    "    else:\n",
    "        print(\"Não foi possível obter dados de temperatura para nenhuma cidade na amostra inicial.\")\n",
    "else:\n",
    "    print(\"Nenhuma cidade encontrada que atenda aos critérios (mais de 10 transações totais e com contagem de clientes).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc7a5064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Exercício 2: Receita Bruta em Cidades com Clima Ameno ---\n",
      "Buscando clima para 30 cidades (Ex2)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dgeis\\AppData\\Local\\Temp\\ipykernel_19340\\720489529.py:10: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql_query(sql, db_conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cidades (amostra) com clima ameno (18°C-24°C) e sua receita:\n",
      "+----+-------------+-----------------+---------------+\n",
      "|    | city        |   receita_bruta |   temperatura |\n",
      "|----+-------------+-----------------+---------------|\n",
      "|  2 | Saint-Denis |          216.54 |          21.1 |\n",
      "| 13 | Skikda      |          173.63 |          19.7 |\n",
      "+----+-------------+-----------------+---------------+\n",
      "\n",
      "Faturamento total (amostra) vindo de cidades com clima ameno (18°C-24°C): $390.17\n"
     ]
    }
   ],
   "source": [
    "# Exercício 2 – Receita Bruta em Cidades com Clima Ameno\n",
    "\n",
    "print(\"\\n--- Exercício 2: Receita Bruta em Cidades com Clima Ameno ---\")\n",
    "\n",
    "# 1. Calcule a receita bruta por cidade.\n",
    "query_receita_cidade = \"\"\"\n",
    "SELECT\n",
    "    ci.city,\n",
    "    SUM(p.amount) AS receita_bruta\n",
    "FROM payment p\n",
    "JOIN customer c ON p.customer_id = c.customer_id\n",
    "JOIN address a ON c.address_id = a.address_id\n",
    "JOIN city ci ON a.city_id = ci.city_id\n",
    "GROUP BY ci.city\n",
    "ORDER BY receita_bruta DESC;\n",
    "\"\"\"\n",
    "df_receita_cidades_ex2 = run_query(query_receita_cidade)\n",
    "\n",
    "if not df_receita_cidades_ex2.empty:\n",
    "    # 2. Use a WeatherAPI para consultar a temperatura atual.\n",
    "    # Amostra para agilidade, ou todas se cache estiver bom.\n",
    "    # Criar uma cópia explícita para evitar SettingWithCopyWarning\n",
    "    cidades_para_clima_ex2 = df_receita_cidades_ex2.head(30).copy() # <--- ADICIONADO .copy()\n",
    "    # Para todas: cidades_para_clima_ex2 = df_receita_cidades_ex2.copy()\n",
    "\n",
    "    print(f\"Buscando clima para {len(cidades_para_clima_ex2)} cidades (Ex2)...\")\n",
    "    # Usar .loc para atribuir a nova coluna de forma segura\n",
    "    cidades_para_clima_ex2.loc[:, 'temperatura'] = cidades_para_clima_ex2['city'].apply(buscar_clima) # <--- USADO .loc\n",
    "\n",
    "    # Criar df_receita_clima_ex2 como uma cópia após o dropna\n",
    "    df_receita_clima_ex2 = cidades_para_clima_ex2.dropna(subset=['temperatura']).copy() # <--- ADICIONADO .copy()\n",
    "\n",
    "    if not df_receita_clima_ex2.empty: # Checa se, após buscar clima e remover NaNs, ainda temos dados\n",
    "        # Usar .loc para as modificações subsequentes\n",
    "        df_receita_clima_ex2.loc[:, 'temperatura'] = pd.to_numeric(df_receita_clima_ex2['temperatura'], errors='coerce') # <--- USADO .loc\n",
    "        # Em vez de inplace=True, é mais seguro reatribuir o resultado do dropna.\n",
    "        # E como já fizemos um .dropna().copy() antes, esta linha de dropna pode ser para garantir após o to_numeric.\n",
    "        df_receita_clima_ex2 = df_receita_clima_ex2.dropna(subset=['temperatura']) # <--- Reatribuição em vez de inplace=True\n",
    "\n",
    "        if not df_receita_clima_ex2.empty: # Checa novamente após a conversão numérica\n",
    "            # 3. Filtre apenas cidades com temperatura entre 18°C e 24°C.\n",
    "            # Esta operação de filtro cria uma nova cópia (ou view), se for modificada depois, precisaria de .copy()\n",
    "            df_clima_ameno_ex2 = df_receita_clima_ex2[\n",
    "                (df_receita_clima_ex2['temperatura'] >= 18) & (df_receita_clima_ex2['temperatura'] <= 24)\n",
    "            ]\n",
    "            # Se df_clima_ameno_ex2 for ser modificado posteriormente, use .copy():\n",
    "            # df_clima_ameno_ex2 = df_receita_clima_ex2[...].copy()\n",
    "\n",
    "            if not df_clima_ameno_ex2.empty:\n",
    "                print(\"\\nCidades (amostra) com clima ameno (18°C-24°C) e sua receita:\")\n",
    "                print(tabulate(df_clima_ameno_ex2[['city', 'receita_bruta', 'temperatura']].head(), headers=\"keys\", tablefmt=\"psql\"))\n",
    "\n",
    "                # 4. Resultado: qual o faturamento total vindo dessas cidades?\n",
    "                faturamento_total_ameno = df_clima_ameno_ex2['receita_bruta'].sum()\n",
    "                print(f\"\\nFaturamento total (amostra) vindo de cidades com clima ameno (18°C-24°C): ${faturamento_total_ameno:,.2f}\")\n",
    "            else:\n",
    "                print(\"Nenhuma cidade na amostra encontrada com clima ameno no intervalo especificado e dados de temperatura válidos.\")\n",
    "        else:\n",
    "            print(\"Amostra de cidades ficou vazia após tentativa de conversão numérica da temperatura.\")\n",
    "    else:\n",
    "        print(\"Não foi possível obter dados de temperatura para as cidades com receita (Ex2).\")\n",
    "else:\n",
    "    print(\"Não foi possível calcular a receita bruta por cidade (Ex2).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e99d7a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Exercício 3: Aluguel de Filmes por País e População ---\n",
      "Buscando dados de população/região para 108 países (Ex3)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dgeis\\AppData\\Local\\Temp\\ipykernel_19340\\720489529.py:10: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql_query(sql, db_conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Países mais 'cinéfilos' (aluguéis por 1.000 habitantes):\n",
      "+----+-------------------------------+----------------+--------------+-------------------------+\n",
      "|    | country                       |   num_alugueis |   population |   alugueis_por_1000_hab |\n",
      "|----+-------------------------------+----------------+--------------+-------------------------|\n",
      "| 73 | Holy See (Vatican City State) |             34 |          451 |                75.388   |\n",
      "| 14 | Iran                          |            225 |        18100 |                12.4309  |\n",
      "| 27 | Netherlands                   |            134 |        25987 |                 5.15642 |\n",
      "| 78 | Nauru                         |             31 |        10834 |                 2.86136 |\n",
      "| 68 | Anguilla                      |             35 |        13452 |                 2.60184 |\n",
      "+----+-------------------------------+----------------+--------------+-------------------------+\n"
     ]
    }
   ],
   "source": [
    "# 6: Exercício 3 – Aluguel de Filmes por Região e População\n",
    "\n",
    "print(\"\\n--- Exercício 3: Aluguel de Filmes por País e População ---\")\n",
    "\n",
    "# 1. Identifique os países dos clientes com maior número de aluguéis.\n",
    "query_alugueis_pais = \"\"\"\n",
    "SELECT\n",
    "    co.country,\n",
    "    COUNT(r.rental_id) AS num_alugueis\n",
    "FROM rental r\n",
    "JOIN customer cu ON r.customer_id = cu.customer_id\n",
    "JOIN address a ON cu.address_id = a.address_id\n",
    "JOIN city ci ON a.city_id = ci.city_id\n",
    "JOIN country co ON ci.country_id = co.country_id\n",
    "GROUP BY co.country\n",
    "ORDER BY num_alugueis DESC;\n",
    "\"\"\"\n",
    "df_alugueis_pais_ex3 = run_query(query_alugueis_pais).copy() # <--- ADICIONADO .copy()\n",
    "\n",
    "if not df_alugueis_pais_ex3.empty:\n",
    "    # 2. Use a REST Countries API para obter a população desses países.\n",
    "    # Trabalhar com todos os países do resultado da query, pois buscar_dados_pais usa cache.\n",
    "    print(f\"Buscando dados de população/região para {len(df_alugueis_pais_ex3)} países (Ex3)...\")\n",
    "    \n",
    "    # Aplicar a função para buscar dados da API\n",
    "    # A função buscar_dados_pais retorna um dicionário, vamos expandi-lo em colunas\n",
    "    country_data_list = []\n",
    "    for country_name in df_alugueis_pais_ex3['country']:\n",
    "        data = buscar_dados_pais(country_name)\n",
    "        if data:\n",
    "            country_data_list.append({\n",
    "                'country': country_name, # Chave para o merge\n",
    "                'population': data.get('population'),\n",
    "                'region': data.get('region') # Continente\n",
    "            })\n",
    "        else:\n",
    "            country_data_list.append({\n",
    "                'country': country_name,\n",
    "                'population': np.nan,\n",
    "                'region': None\n",
    "            })\n",
    "    \n",
    "    df_country_info_ex3 = pd.DataFrame(country_data_list)\n",
    "    \n",
    "    # Merge com df_alugueis_pais\n",
    "    df_analise_pais_ex3 = pd.merge(df_alugueis_pais_ex3, df_country_info_ex3, on='country', how='left')\n",
    "    \n",
    "    df_analise_pais_ex3.dropna(subset=['population'], inplace=True)\n",
    "    df_analise_pais_ex3['population'] = pd.to_numeric(df_analise_pais_ex3['population'], errors='coerce')\n",
    "    df_analise_pais_ex3.dropna(subset=['population'], inplace=True)\n",
    "\n",
    "    if not df_analise_pais_ex3.empty and df_analise_pais_ex3['population'].sum() > 0 :\n",
    "        # 3. Calcule o número de aluguéis por 1.000 habitantes.\n",
    "        df_analise_pais_ex3['alugueis_por_1000_hab'] = \\\n",
    "            (df_analise_pais_ex3['num_alugueis'] / df_analise_pais_ex3['population']) * 1000\n",
    "        \n",
    "        # 4. Análise: quais países são mais “cinéfilos” proporcionalmente?\n",
    "        df_cinefilos_ex3 = df_analise_pais_ex3.sort_values(by='alugueis_por_1000_hab', ascending=False)\n",
    "        print(\"\\nPaíses mais 'cinéfilos' (aluguéis por 1.000 habitantes):\")\n",
    "        print(tabulate(df_cinefilos_ex3[['country', 'num_alugueis', 'population', 'alugueis_por_1000_hab']].head(), headers=\"keys\", tablefmt=\"psql\"))\n",
    "    else:\n",
    "        print(\"Não foi possível calcular aluguéis por 1000 habitantes (sem dados de população válidos ou população total é zero).\")\n",
    "else:\n",
    "    print(\"Não foi possível obter o número de aluguéis por país (Ex3).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a546a91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Exercício 4: Filmes Mais Populares em Cidades Poluídas ---\n",
      "\n",
      "Top 10 cidades com maior número de clientes (com detalhes para AQI):\n",
      "+----+--------------------+----------------------+----------------------+----------------+\n",
      "|    | city               | district             | country_pagila       |   num_clientes |\n",
      "|----+--------------------+----------------------+----------------------+----------------|\n",
      "|  0 | Abu Dhabi          | Abu Dhabi            | United Arab Emirates |              1 |\n",
      "|  1 | A Corua (La Corua) | Galicia              | Spain                |              1 |\n",
      "|  2 | Acua               | Coahuila de Zaragoza | Mexico               |              1 |\n",
      "|  3 | Adana              | Adana                | Turkey               |              1 |\n",
      "|  4 | Addis Abeba        | Addis Abeba          | Ethiopia             |              1 |\n",
      "|  5 | Aden               | Aden                 | Yemen                |              1 |\n",
      "|  6 | Adoni              | Andhra Pradesh       | India                |              1 |\n",
      "|  7 | Ahmadnagar         | Maharashtra          | India                |              1 |\n",
      "|  8 | Akishima           | Tokyo-to             | Japan                |              1 |\n",
      "|  9 | Abha               | Asir                 | Saudi Arabia         |              1 |\n",
      "+----+--------------------+----------------------+----------------------+----------------+\n",
      "\n",
      "Buscando AQI para as top cidades (Ex4)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dgeis\\AppData\\Local\\Temp\\ipykernel_19340\\720489529.py:10: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql_query(sql, db_conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top cidades com AQI:\n",
      "+----+-----------+----------------------+----------------+-------+\n",
      "|    | city      | country_pagila       |   num_clientes |   aqi |\n",
      "|----+-----------+----------------------+----------------+-------|\n",
      "|  0 | Abu Dhabi | United Arab Emirates |              1 |   156 |\n",
      "+----+-----------+----------------------+----------------+-------+\n",
      "\n",
      "Cidades (da amostra top 10) consideradas poluídas (AQI > 150):\n",
      "+----+-----------+----------------------+-------+\n",
      "|    | city      | country_pagila       |   aqi |\n",
      "|----+-----------+----------------------+-------|\n",
      "|  0 | Abu Dhabi | United Arab Emirates |   156 |\n",
      "+----+-----------+----------------------+-------+\n",
      "\n",
      "Filmes mais alugados em cidades poluídas (AQI > 150) da amostra:\n",
      "\n",
      "Top filmes para Abu Dhabi:\n",
      "+---------------------+----------------+\n",
      "| filme_titulo        |   num_alugueis |\n",
      "|---------------------+----------------|\n",
      "| GENTLEMEN STAGE     |              2 |\n",
      "| BLINDNESS GUN       |              1 |\n",
      "| BORROWERS BEDAZZLED |              1 |\n",
      "| CADDYSHACK JEDI     |              1 |\n",
      "| CLUELESS BUCKET     |              1 |\n",
      "+---------------------+----------------+\n",
      "\n",
      "Discussão (Exercício 4):\n",
      "Esta análise é preliminar. Para determinar se a poluição impacta as preferências de filmes, seria necessário:\n",
      "  - Amostra maior de cidades e dados de AQI mais abrangentes e precisos.\n",
      "  - Comparar gêneros/tipos de filmes populares em cidades poluídas vs. não poluídas (controlando por outros fatores).\n",
      "  - Análise estatística para verificar correlações significativas, idealmente controlando por variáveis confundidoras (cultura, renda, etc.).\n",
      "A simples listagem atual não permite conclusões causais.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dgeis\\AppData\\Local\\Temp\\ipykernel_19340\\720489529.py:10: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql_query(sql, db_conn)\n"
     ]
    }
   ],
   "source": [
    "# Exercício 4 – Filmes Mais Populares em Cidades Poluídas\n",
    "\n",
    "print(\"\\n--- Exercício 4: Filmes Mais Populares em Cidades Poluídas ---\")\n",
    "\n",
    "if not AIRVISUAL_API_KEY:\n",
    "    print(\"Chave da API AirVisual (AIRVISUAL_KEY) não encontrada no .env. Pulando Exercício 4.\")\n",
    "else:\n",
    "    # 1. Liste as 10 cidades com maior número de clientes.\n",
    "    #    A query precisa de cidade, distrito (para estado), e país para a API AirVisual.\n",
    "    query_top_cidades_clientes_detalhes = \"\"\"\n",
    "    SELECT\n",
    "        ci.city,\n",
    "        a.district, -- Usaremos como 'estado' para a API AirVisual\n",
    "        cy.country AS country_pagila, -- Nome original do Pagila\n",
    "        COUNT(DISTINCT c.customer_id) AS num_clientes\n",
    "    FROM customer c\n",
    "    JOIN address a ON c.address_id = a.address_id\n",
    "    JOIN city ci ON a.city_id = ci.city_id\n",
    "    JOIN country cy ON ci.country_id = cy.country_id\n",
    "    GROUP BY ci.city, a.district, cy.country\n",
    "    ORDER BY num_clientes DESC\n",
    "    LIMIT 10;\n",
    "    \"\"\"\n",
    "    df_top_cidades_clientes_ex4 = run_query(query_top_cidades_clientes_detalhes)\n",
    "\n",
    "    if not df_top_cidades_clientes_ex4.empty:\n",
    "        print(\"\\nTop 10 cidades com maior número de clientes (com detalhes para AQI):\")\n",
    "        print(tabulate(df_top_cidades_clientes_ex4, headers=\"keys\", tablefmt=\"psql\"))\n",
    "\n",
    "        # Mapeamento de nomes de país do Pagila para os esperados pela AirVisual (geralmente inglês padrão)\n",
    "        # Este mapa é um exemplo e pode precisar de ajustes.\n",
    "        country_name_map_airvisual = { \n",
    "            \"United States\": \"USA\", \n",
    "            \"Russian Federation\": \"Russia\", \n",
    "            \"Viet Nam\": \"Vietnam\",\n",
    "            \"Iran (Islamic Republic of)\": \"Iran\", \n",
    "            \"Czech Republic\": \"Czech Republic\", #Manter para ver se funciona\n",
    "            \"Holy See (Vatican City State)\": \"Vatican City State\", \n",
    "            \"RUNION\": \"France\" # Reunion é da França\n",
    "            # Adicione outros mapeamentos se necessário, baseados nos países de suas top cidades\n",
    "        }\n",
    "        \n",
    "        # 2. Use a AirVisual API para consultar o AQI dessas cidades.\n",
    "        print(\"\\nBuscando AQI para as top cidades (Ex4)...\")\n",
    "        aqi_data = []\n",
    "        for _, row in df_top_cidades_clientes_ex4.iterrows():\n",
    "            cidade = row['city']\n",
    "            distrito = row['district']\n",
    "            pais_pagila = row['country_pagila']\n",
    "            # Usar o nome do país mapeado para a API AirVisual, ou o original se não estiver no mapa\n",
    "            pais_api = country_name_map_airvisual.get(pais_pagila, pais_pagila)\n",
    "            \n",
    "            # Tentar com distrito, depois com cidade como estado se distrito for problemático\n",
    "            current_aqi = buscar_aqi_cidade(cidade, distrito, pais_api)\n",
    "            if current_aqi is None and (distrito.lower() == cidade.lower() or len(distrito.split()) > 2 or distrito in ['N/A', '']): # Heurística\n",
    "                # print(f\"Retrying AQI for {cidade} with state={cidade}, country={pais_api}\")\n",
    "                current_aqi = buscar_aqi_cidade(cidade, cidade, pais_api)\n",
    "            \n",
    "            aqi_data.append({'city': cidade, 'district': distrito, 'country_pagila': pais_pagila, 'aqi': current_aqi})\n",
    "        \n",
    "        df_top_cidades_aqi_ex4 = pd.DataFrame(aqi_data)\n",
    "        df_top_cidades_aqi_ex4 = pd.merge(df_top_cidades_clientes_ex4, df_top_cidades_aqi_ex4, on=['city', 'district', 'country_pagila'])\n",
    "        df_top_cidades_aqi_ex4['aqi'] = pd.to_numeric(df_top_cidades_aqi_ex4['aqi'], errors='coerce')\n",
    "        \n",
    "        print(\"\\nTop cidades com AQI:\")\n",
    "        print(tabulate(df_top_cidades_aqi_ex4[['city', 'country_pagila', 'num_clientes', 'aqi']].dropna(subset=['aqi']), headers=\"keys\", tablefmt=\"psql\"))\n",
    "\n",
    "        # 3. Relacione os filmes mais alugados em cidades com AQI > 150.\n",
    "        cidades_poluidas_ex4 = df_top_cidades_aqi_ex4[df_top_cidades_aqi_ex4['aqi'] > 150]\n",
    "        \n",
    "        if not cidades_poluidas_ex4.empty:\n",
    "            print(\"\\nCidades (da amostra top 10) consideradas poluídas (AQI > 150):\")\n",
    "            print(tabulate(cidades_poluidas_ex4[['city', 'country_pagila', 'aqi']], headers=\"keys\", tablefmt=\"psql\"))\n",
    "            \n",
    "            lista_cidades_poluidas_nomes = cidades_poluidas_ex4['city'].unique().tolist()\n",
    "            \n",
    "            if lista_cidades_poluidas_nomes:\n",
    "                cidades_sql_formato = \", \".join([\"'%s'\" % c.replace(\"'\", \"''\") for c in lista_cidades_poluidas_nomes])\n",
    "                query_filmes_cidades_poluidas = f\"\"\"\n",
    "                SELECT\n",
    "                    f.title AS filme_titulo,\n",
    "                    ci.city,\n",
    "                    COUNT(r.rental_id) AS num_alugueis\n",
    "                FROM rental r\n",
    "                JOIN inventory i ON r.inventory_id = i.inventory_id\n",
    "                JOIN film f ON i.film_id = f.film_id\n",
    "                JOIN customer cu ON r.customer_id = cu.customer_id\n",
    "                JOIN address a ON cu.address_id = a.address_id\n",
    "                JOIN city ci ON a.city_id = ci.city_id\n",
    "                WHERE ci.city IN ({cidades_sql_formato})\n",
    "                GROUP BY f.title, ci.city\n",
    "                ORDER BY ci.city, num_alugueis DESC;\n",
    "                \"\"\"\n",
    "                df_filmes_poluidas_ex4 = run_query(query_filmes_cidades_poluidas)\n",
    "                \n",
    "                if not df_filmes_poluidas_ex4.empty:\n",
    "                    print(\"\\nFilmes mais alugados em cidades poluídas (AQI > 150) da amostra:\")\n",
    "                    for cidade_nome in lista_cidades_poluidas_nomes:\n",
    "                        print(f\"\\nTop filmes para {cidade_nome}:\")\n",
    "                        top_filmes_cidade = df_filmes_poluidas_ex4[df_filmes_poluidas_ex4['city'] == cidade_nome].head()\n",
    "                        if not top_filmes_cidade.empty:\n",
    "                             print(tabulate(top_filmes_cidade[['filme_titulo', 'num_alugueis']], headers=\"keys\", tablefmt=\"psql\", showindex=False))\n",
    "                        else:\n",
    "                            print(\"Nenhum dado de aluguel encontrado para esta cidade.\")\n",
    "                else:\n",
    "                    print(\"Nenhum filme encontrado para as cidades poluídas selecionadas na amostra.\")\n",
    "            else: # teoricamente não deve acontecer se cidades_poluidas_ex4 não for empty\n",
    "                print(\"Nenhuma cidade poluída (AQI > 150) encontrada na amostra das top 10 cidades.\")\n",
    "        else:\n",
    "            print(\"Nenhuma cidade com AQI > 150 encontrada na amostra das top 10 cidades com dados de AQI válidos.\")\n",
    "\n",
    "        # 4. Discussão: poluição impacta preferências de filmes?\n",
    "        print(\"\\nDiscussão (Exercício 4):\")\n",
    "        print(\"Esta análise é preliminar. Para determinar se a poluição impacta as preferências de filmes, seria necessário:\")\n",
    "        print(\"  - Amostra maior de cidades e dados de AQI mais abrangentes e precisos.\")\n",
    "        print(\"  - Comparar gêneros/tipos de filmes populares em cidades poluídas vs. não poluídas (controlando por outros fatores).\")\n",
    "        print(\"  - Análise estatística para verificar correlações significativas, idealmente controlando por variáveis confundidoras (cultura, renda, etc.).\")\n",
    "        print(\"A simples listagem atual não permite conclusões causais.\")\n",
    "    else:\n",
    "        print(\"Nenhuma cidade encontrada na query inicial de top clientes (Ex4).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "408187f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Exercício 5: Clientes em Áreas Críticas (AQI > 130) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dgeis\\AppData\\Local\\Temp\\ipykernel_19340\\720489529.py:10: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql_query(sql, db_conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Buscando AQI e temperatura para TODAS as 599 cidades de clientes (Ex5).\n",
      "AVISO: Esta etapa pode ser demorada na primeira execução completa, pois consultará APIs para muitas cidades.\n",
      "As execuções subsequentes serão mais rápidas devido ao cache.\n",
      "\n",
      "Processando cidade 1/599: Kabul, Afghanistan...\n",
      "Processando cidade 50/599: Sagamihara, Japan...\n",
      "Processando cidade 100/599: Callao, Peru...\n",
      "Processando cidade 150/599: Santa Brbara dOeste, Brazil...\n",
      "Processando cidade 200/599: Tabora, Tanzania...\n",
      "Processando cidade 250/599: Jaipur, India...\n",
      "Processando cidade 300/599: Pereira, Colombia...\n",
      "Processando cidade 350/599: Dadu, Pakistan...\n",
      "Processando cidade 400/599: Urawa, Japan...\n",
      "Processando cidade 450/599: Lausanne, Switzerland...\n",
      "Processando cidade 500/599: Chandrapur, India...\n",
      "Processando cidade 550/599: Nam Dinh, Vietnam...\n",
      "Processando cidade 599/599: al-Hawiya, Saudi Arabia...\n",
      "\n",
      "Cidades encontradas com AQI > 130:\n",
      "+-----+-----------+----------------------+-------+---------------+\n",
      "|     | city      | country_pagila       |   aqi |   temperatura |\n",
      "|-----+-----------+----------------------+-------+---------------|\n",
      "| 345 | Abu Dhabi | United Arab Emirates |   156 |          28.2 |\n",
      "+-----+-----------+----------------------+-------+---------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dgeis\\AppData\\Local\\Temp\\ipykernel_19340\\720489529.py:10: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql_query(sql, db_conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clientes em áreas críticas (AQI > 130) com detalhes:\n",
      "+----+---------------+--------------+-------------+-----------+----------------------+-------+---------------+\n",
      "|    |   customer_id | first_name   | last_name   | city      | country_pagila       |   aqi |   temperatura |\n",
      "|----+---------------+--------------+-------------+-----------+----------------------+-------+---------------|\n",
      "|  0 |           452 | TOM          | MILNER      | Abu Dhabi | United Arab Emirates |   156 |          28.2 |\n",
      "+----+---------------+--------------+-------------+-----------+----------------------+-------+---------------+\n",
      "\n",
      "Clientes classificados em 'Zona de Atenção Ambiental':\n",
      "+----+--------------+-------------+-----------+----------------------+---------------+-------+--------------------------+\n",
      "|    | first_name   | last_name   | city      | country_pagila       |   temperatura |   aqi | zona_atencao_ambiental   |\n",
      "|----+--------------+-------------+-----------+----------------------+---------------+-------+--------------------------|\n",
      "|  0 | TOM          | MILNER      | Abu Dhabi | United Arab Emirates |          28.2 |   156 | Sim (AQI > 130)          |\n",
      "+----+--------------+-------------+-----------+----------------------+---------------+-------+--------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Exercício 5 – Clientes em Áreas Críticas (Corrigido para analisar TODAS as cidades)\n",
    "\n",
    "print(\"\\n--- Exercício 5: Clientes em Áreas Críticas (AQI > 130) ---\")\n",
    "\n",
    "if not AIRVISUAL_API_KEY:\n",
    "    print(\"Chave da API AirVisual (AIRVISUAL_KEY) não encontrada no .env. Pulando Exercício 5.\")\n",
    "else:\n",
    "    # 1. Obter TODAS as cidades distintas dos clientes\n",
    "    query_cidades_clientes_detalhes_ex5 = \"\"\"\n",
    "    SELECT DISTINCT\n",
    "        ci.city,\n",
    "        a.district,\n",
    "        cy.country AS country_pagila\n",
    "    FROM customer c\n",
    "    JOIN address a ON c.address_id = a.address_id\n",
    "    JOIN city ci ON a.city_id = ci.city_id\n",
    "    JOIN country cy ON ci.country_id = cy.country_id;\n",
    "    \"\"\"\n",
    "    df_cidades_all_clientes_ex5 = run_query(query_cidades_clientes_detalhes_ex5)\n",
    "\n",
    "    if not df_cidades_all_clientes_ex5.empty:\n",
    "\n",
    "        cidades_para_verificar_ex5 = df_cidades_all_clientes_ex5.copy() # Usar todas as cidades\n",
    "\n",
    "        print(f\"\\nBuscando AQI e temperatura para TODAS as {len(cidades_para_verificar_ex5)} cidades de clientes (Ex5).\")\n",
    "        print(\"AVISO: Esta etapa pode ser demorada na primeira execução completa, pois consultará APIs para muitas cidades.\")\n",
    "        print(\"As execuções subsequentes serão mais rápidas devido ao cache.\\n\")\n",
    "        \n",
    "        country_name_map_airvisual_ex5 = country_name_map_airvisual # Definido no Ex4 e reutilizado\n",
    "\n",
    "        enriched_cities_data = []\n",
    "        for index, row in cidades_para_verificar_ex5.iterrows(): # Iterar sobre TODAS as cidades\n",
    "            cidade = row['city']\n",
    "            distrito = row['district']\n",
    "            pais_pagila = row['country_pagila']\n",
    "            pais_api_aqi = country_name_map_airvisual_ex5.get(pais_pagila, pais_pagila)\n",
    "            \n",
    "            # Adicionar feedback de progresso (opcional, mas útil para execuções longas)\n",
    "            if (index + 1) % 50 == 0 or index == 0 or (index + 1) == len(cidades_para_verificar_ex5) : # A cada 50 cidades, ou na primeira/última\n",
    "                print(f\"Processando cidade {index + 1}/{len(cidades_para_verificar_ex5)}: {cidade}, {pais_pagila}...\")\n",
    "\n",
    "            current_aqi = buscar_aqi_cidade(cidade, distrito, pais_api_aqi) # USA O CACHE\n",
    "            if current_aqi is None and (distrito.lower() == cidade.lower() or len(distrito.split()) > 2 or distrito in ['N/A', '']):\n",
    "                current_aqi = buscar_aqi_cidade(cidade, cidade, pais_api_aqi) # USA O CACHE\n",
    "            \n",
    "            current_temp = buscar_clima(cidade) # USA O CACHE\n",
    "            \n",
    "            enriched_cities_data.append({\n",
    "                'city': cidade, 'district': distrito, 'country_pagila': pais_pagila,\n",
    "                'aqi': current_aqi, 'temperatura': current_temp\n",
    "            })\n",
    "            # Considerar um pequeno time.sleep(0.05) ou similar aqui se o cache estiver falhando muito e sobrecarregando as APIs\n",
    "        \n",
    "        df_enriched_cities_ex5 = pd.DataFrame(enriched_cities_data)\n",
    "        df_enriched_cities_ex5['aqi'] = pd.to_numeric(df_enriched_cities_ex5['aqi'], errors='coerce')\n",
    "        df_enriched_cities_ex5['temperatura'] = pd.to_numeric(df_enriched_cities_ex5['temperatura'], errors='coerce')\n",
    "\n",
    "        # Filtrar cidades com AQI > 130\n",
    "        cidades_aqi_critico_ex5 = df_enriched_cities_ex5[df_enriched_cities_ex5['aqi'] > 130].copy()\n",
    "\n",
    "        if not cidades_aqi_critico_ex5.empty:\n",
    "            print(\"\\nCidades encontradas com AQI > 130:\")\n",
    "            print(tabulate(cidades_aqi_critico_ex5[['city', 'country_pagila', 'aqi', 'temperatura']].dropna(subset=['aqi']), headers=\"keys\", tablefmt=\"psql\"))\n",
    "            \n",
    "            # Obter nomes únicos das cidades críticas para a query SQL\n",
    "            lista_cidades_criticas_nomes_validas = [\n",
    "                str(nome_cidade) for nome_cidade in cidades_aqi_critico_ex5['city'].unique().tolist() \n",
    "                if pd.notna(nome_cidade) and str(nome_cidade).strip() != \"\"\n",
    "            ]\n",
    "            \n",
    "            if lista_cidades_criticas_nomes_validas:\n",
    "                cidades_criticas_sql = \", \".join([f\"'{c.replace(\"'\", \"''\")}'\" for c in lista_cidades_criticas_nomes_validas])\n",
    "                query_clientes_areas_criticas = f\"\"\"\n",
    "                SELECT\n",
    "                    cu.customer_id,\n",
    "                    cu.first_name,\n",
    "                    cu.last_name,\n",
    "                    ci.city,\n",
    "                    cy.country AS country_pagila\n",
    "                FROM customer cu\n",
    "                JOIN address a ON cu.address_id = a.address_id\n",
    "                JOIN city ci ON a.city_id = ci.city_id\n",
    "                JOIN country cy ON ci.country_id = cy.country_id\n",
    "                WHERE ci.city IN ({cidades_criticas_sql});\n",
    "                \"\"\"\n",
    "                df_clientes_criticos_ex5 = run_query(query_clientes_areas_criticas)\n",
    "\n",
    "                if not df_clientes_criticos_ex5.empty:\n",
    "                    # 2. Combine nome do cliente, cidade, país, temperatura e AQI.\n",
    "                    df_clientes_criticos_detalhes_ex5 = pd.merge(\n",
    "                        df_clientes_criticos_ex5,\n",
    "                        cidades_aqi_critico_ex5[['city', 'country_pagila', 'aqi', 'temperatura']],\n",
    "                        on=['city', 'country_pagila'],\n",
    "                        how='inner' \n",
    "                    )\n",
    "                    \n",
    "                    print(\"\\nClientes em áreas críticas (AQI > 130) com detalhes:\")\n",
    "                    if not df_clientes_criticos_detalhes_ex5.empty:\n",
    "                        print(tabulate(df_clientes_criticos_detalhes_ex5.head(), headers=\"keys\", tablefmt=\"psql\"))\n",
    "\n",
    "                        # 3. Classifique os clientes em “zona de atenção” com base nos critérios ambientais.\n",
    "                        df_clientes_criticos_detalhes_ex5.loc[:, 'zona_atencao_ambiental'] = 'Sim (AQI > 130)'\n",
    "                        print(\"\\nClientes classificados em 'Zona de Atenção Ambiental':\")\n",
    "                        print(tabulate(df_clientes_criticos_detalhes_ex5[['first_name', 'last_name', 'city', 'country_pagila', 'temperatura', 'aqi', 'zona_atencao_ambiental']].head(), headers=\"keys\", tablefmt=\"psql\"))\n",
    "                    else:\n",
    "                        print(\"Nenhum cliente encontrado nas cidades críticas identificadas (após merge com dados de AQI/Temp).\")\n",
    "                else:\n",
    "                    print(\"Nenhum cliente encontrado nas cidades com AQI > 130 (após validação de nomes).\")\n",
    "            else:\n",
    "                print(\"Nenhuma cidade crítica com nome válido encontrada para buscar clientes.\")\n",
    "        else:\n",
    "            print(\"Nenhuma cidade com AQI > 130 encontrada após analisar todas as cidades dos clientes.\")\n",
    "    else:\n",
    "        print(\"Nenhuma cidade de cliente encontrada para análise no Ex5.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc61fb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Exercício 6: Receita por Continente ---\n",
      "Erro ao executar query: connection already closed\n",
      "Não foi possível obter receita por país (Ex6).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dgeis\\AppData\\Local\\Temp\\ipykernel_19340\\720489529.py:10: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql_query(sql, db_conn)\n"
     ]
    }
   ],
   "source": [
    "# Exercício 6 – Receita por Continente\n",
    "\n",
    "print(\"\\n--- Exercício 6: Receita por Continente ---\")\n",
    "\n",
    "# 1. Use a REST Countries API para mapear o continente de cada país.\n",
    "# Primeiro, pegar todos os países do banco Pagila e sua receita.\n",
    "query_receita_pais_ex6 = \"\"\"\n",
    "SELECT\n",
    "    co.country AS country_pagila,\n",
    "    SUM(p.amount) AS receita_total\n",
    "FROM payment p\n",
    "JOIN customer cu ON p.customer_id = cu.customer_id\n",
    "JOIN address a ON cu.address_id = a.address_id\n",
    "JOIN city ci ON a.city_id = ci.city_id\n",
    "JOIN country co ON ci.country_id = co.country_id\n",
    "GROUP BY co.country\n",
    "ORDER BY co.country;\n",
    "\"\"\"\n",
    "df_receita_pais_ex6 = run_query(query_receita_pais_ex6)\n",
    "\n",
    "if not df_receita_pais_ex6.empty:\n",
    "    print(f\"Buscando dados de região (continente) para {len(df_receita_pais_ex6)} países (Ex6)...\")\n",
    "    \n",
    "    country_region_data = []\n",
    "    for country_name_pg in df_receita_pais_ex6['country_pagila']:\n",
    "        data = buscar_dados_pais(country_name_pg) # Usa o cache\n",
    "        if data and data.get('region'):\n",
    "            country_region_data.append({\n",
    "                'country_pagila': country_name_pg,\n",
    "                'region': data['region'] \n",
    "            })\n",
    "        else:\n",
    "            country_region_data.append({\n",
    "                'country_pagila': country_name_pg,\n",
    "                'region': 'N/A (ou desconhecido)'\n",
    "            })\n",
    "            # print(f\"Região não encontrada para {country_name_pg}\")\n",
    "\n",
    "    df_paises_com_regiao_ex6 = pd.DataFrame(country_region_data).copy() # <--- ADICIONADO .copy()\n",
    "    \n",
    "    # Merge com df_receita_pais\n",
    "    df_receita_pais_regiao_ex6 = pd.merge(df_receita_pais_ex6, df_paises_com_regiao_ex6, on='country_pagila', how='left')\n",
    "    df_receita_pais_regiao_ex6.dropna(subset=['region'], inplace=True)\n",
    "    df_receita_pais_regiao_ex6 = df_receita_pais_regiao_ex6[~df_receita_pais_regiao_ex6['region'].str.contains('N/A', case=False)]\n",
    "\n",
    "    if not df_receita_pais_regiao_ex6.empty:\n",
    "        # 2. Agrupe a receita total por continente (region).\n",
    "        receita_por_continente_ex6 = df_receita_pais_regiao_ex6.groupby('region')['receita_total'].sum().sort_values(ascending=False)\n",
    "        print(\"\\nReceita total por continente:\")\n",
    "        # print(receita_por_continente_ex6)\n",
    "        print(tabulate(pd.DataFrame(receita_por_continente_ex6), headers=['Continente', 'Receita Total'], tablefmt=\"psql\"))\n",
    "\n",
    "\n",
    "        # 3. Exiba os resultados em um gráfico de pizza com matplotlib.\n",
    "        if not receita_por_continente_ex6.empty:\n",
    "            plt.figure(figsize=(12, 9)) # Ajustado para melhor visualização\n",
    "            ax = receita_por_continente_ex6.plot(kind='pie', \n",
    "                                                 autopct='%1.1f%%', \n",
    "                                                 startangle=140, \n",
    "                                                 wedgeprops=dict(width=0.5, edgecolor='w'),\n",
    "                                                 legend=False) # Desativa legenda automática do pandas para usar plt.legend\n",
    "            plt.title('Distribuição da Receita Total por Continente', fontsize=16)\n",
    "            plt.ylabel('') \n",
    "            plt.legend(title='Continentes', labels=receita_por_continente_ex6.index, loc=\"center left\", bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "            plt.tight_layout(rect=[0,0,0.8,1]) # Ajustar para legenda não sobrepor\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Não há dados de receita por continente para plotar.\")\n",
    "    else:\n",
    "        print(\"Não foi possível obter dados de receita por região para gerar o gráfico (Ex6).\")\n",
    "else:\n",
    "    print(\"Não foi possível obter receita por país (Ex6).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e55b73db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Exercício 7: Tempo Médio de Aluguel vs Clima ---\n",
      "Erro ao executar query: connection already closed\n",
      "Não foram encontrados dados de tempo médio de aluguel para as cidades (Ex7).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dgeis\\AppData\\Local\\Temp\\ipykernel_19340\\720489529.py:10: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql_query(sql, db_conn)\n"
     ]
    }
   ],
   "source": [
    "# Exercício 7 – Tempo Médio de Aluguel vs Clima\n",
    "\n",
    "print(\"\\n--- Exercício 7: Tempo Médio de Aluguel vs Clima ---\")\n",
    "\n",
    "# 1. Calcule o tempo médio de aluguel por cidade.\n",
    "query_tempo_medio_aluguel_cidade = \"\"\"\n",
    "SELECT\n",
    "    ci.city,\n",
    "    AVG(EXTRACT(EPOCH FROM (r.return_date - r.rental_date))) AS tempo_medio_aluguel_segundos,\n",
    "    COUNT(r.rental_id) as num_alugueis_cidade\n",
    "FROM rental r\n",
    "JOIN customer cu ON r.customer_id = cu.customer_id\n",
    "JOIN address a ON cu.address_id = a.address_id\n",
    "JOIN city ci ON a.city_id = ci.city_id\n",
    "WHERE r.return_date IS NOT NULL\n",
    "GROUP BY ci.city\n",
    "HAVING COUNT(r.rental_id) > 20 -- Cidades com pelo menos 20 aluguéis para média mais estável\n",
    "ORDER BY ci.city;\n",
    "\"\"\"\n",
    "df_tempo_aluguel_ex7 = run_query(query_tempo_medio_aluguel_cidade)\n",
    "\n",
    "if not df_tempo_aluguel_ex7.empty:\n",
    "    df_tempo_aluguel_ex7['tempo_medio_aluguel_dias'] = df_tempo_aluguel_ex7['tempo_medio_aluguel_segundos'] / (60*60*24)\n",
    "    \n",
    "    # 2. Combine com a temperatura atual dessas cidades.\n",
    "    # Amostra ou todas, dependendo da eficiência do cache\n",
    "    cidades_para_clima_ex7 = df_tempo_aluguel_ex7.copy() # Usar todas as cidades da query\n",
    "    print(f\"Buscando clima para {len(cidades_para_clima_ex7)} cidades (Ex7)...\")\n",
    "    cidades_para_clima_ex7['temperatura'] = cidades_para_clima_ex7['city'].apply(buscar_clima)\n",
    "    \n",
    "    df_analise_tempo_clima_ex7 = cidades_para_clima_ex7.dropna(subset=['temperatura', 'tempo_medio_aluguel_dias'])\n",
    "    df_analise_tempo_clima_ex7['temperatura'] = pd.to_numeric(df_analise_tempo_clima_ex7['temperatura'], errors='coerce')\n",
    "    df_analise_tempo_clima_ex7.dropna(subset=['temperatura'], inplace=True)\n",
    "    \n",
    "    if not df_analise_tempo_clima_ex7.empty:\n",
    "        print(\"\\nAnálise de Tempo Médio de Aluguel vs. Temperatura (amostra de cidades):\")\n",
    "        print(tabulate(df_analise_tempo_clima_ex7[['city', 'tempo_medio_aluguel_dias', 'temperatura']].head(), headers=\"keys\", tablefmt=\"psql\"))\n",
    "\n",
    "        # 3. Visualize a correlação.\n",
    "        if len(df_analise_tempo_clima_ex7) > 1:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.regplot(data=df_analise_tempo_clima_ex7, x='temperatura', y='tempo_medio_aluguel_dias', \n",
    "                        scatter_kws={'alpha':0.5, 's': df_analise_tempo_clima_ex7['num_alugueis_cidade']/10}, # Tamanho do ponto pelo num de alugueis\n",
    "                        line_kws={'color':'red'})\n",
    "            plt.title('Tempo Médio de Aluguel vs. Temperatura da Cidade', fontsize=15)\n",
    "            plt.xlabel('Temperatura Atual (°C)', fontsize=12)\n",
    "            plt.ylabel('Tempo Médio de Aluguel (dias)', fontsize=12)\n",
    "            plt.grid(True, linestyle='--', alpha=0.7)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            correlacao = df_analise_tempo_clima_ex7['temperatura'].corr(df_analise_tempo_clima_ex7['tempo_medio_aluguel_dias'])\n",
    "            print(f\"\\nCorrelação de Pearson entre temperatura e tempo médio de aluguel: {correlacao:.3f}\")\n",
    "            # Comentário sobre a correlação\n",
    "        else:\n",
    "            print(\"Não há dados suficientes (após limpeza e merge) para gerar o gráfico de correlação.\")\n",
    "    else:\n",
    "        print(\"Não foi possível obter dados combinados de tempo de aluguel e clima para análise (Ex7).\")\n",
    "else:\n",
    "    print(\"Não foram encontrados dados de tempo médio de aluguel para as cidades (Ex7).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c05342e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Exercício 8: Perfil de Clima por Cliente ---\n",
      "Erro ao executar query: connection already closed\n",
      "Não foi possível obter dados base de perfil de cliente (Ex8).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dgeis\\AppData\\Local\\Temp\\ipykernel_19340\\720489529.py:10: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql_query(sql, db_conn)\n"
     ]
    }
   ],
   "source": [
    "# Exercício 8 – Perfil de Clima por Cliente\n",
    "\n",
    "print(\"\\n--- Exercício 8: Perfil de Clima por Cliente ---\")\n",
    "\n",
    "# 1. Para cada cliente, crie um perfil com: cidade, temperatura, AQI, total de aluguéis, gasto total.\n",
    "query_perfil_cliente_base_ex8 = \"\"\"\n",
    "SELECT\n",
    "    c.customer_id,\n",
    "    c.first_name,\n",
    "    c.last_name,\n",
    "    ci.city,\n",
    "    a.district, -- Para AQI\n",
    "    cy.country AS country_pagila, -- Para AQI e Temperatura\n",
    "    COUNT(r.rental_id) AS total_alugueis,\n",
    "    COALESCE(SUM(p.amount), 0) AS gasto_total -- COALESCE para clientes sem pagamentos\n",
    "FROM customer c\n",
    "JOIN address a ON c.address_id = a.address_id\n",
    "JOIN city ci ON a.city_id = ci.city_id\n",
    "JOIN country cy ON ci.country_id = cy.country_id\n",
    "LEFT JOIN rental r ON c.customer_id = r.customer_id\n",
    "LEFT JOIN payment p ON r.rental_id = p.rental_id\n",
    "GROUP BY c.customer_id, c.first_name, c.last_name, ci.city, a.district, cy.country\n",
    "ORDER BY c.customer_id;\n",
    "\"\"\"\n",
    "df_perfil_cliente_base_ex8 = run_query(query_perfil_cliente_base_ex8)\n",
    "\n",
    "if not df_perfil_cliente_base_ex8.empty:\n",
    "    # Para enriquecer com Temp e AQI, precisamos de uma lista de cidades únicas.\n",
    "    df_cidades_unicas_clientes_ex8 = df_perfil_cliente_base_ex8[['city', 'district', 'country_pagila']].drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    # AMOSTRAGEM FORTE para demonstração, pois buscar AQI/Temp para todas as cidades de todos os clientes pode ser muito longo.\n",
    "    # Ajuste SAMPLE_SIZE conforme a eficiência do seu cache e paciência.\n",
    "    SAMPLE_SIZE_CITIES_EX8 = min(30, len(df_cidades_unicas_clientes_ex8)) \n",
    "    df_cidades_amostra_ex8 = df_cidades_unicas_clientes_ex8.sample(n=SAMPLE_SIZE_CITIES_EX8, random_state=123) \\\n",
    "        if len(df_cidades_unicas_clientes_ex8) > SAMPLE_SIZE_CITIES_EX8 else df_cidades_unicas_clientes_ex8.copy()\n",
    "\n",
    "    print(f\"\\nBuscando dados ambientais para uma AMOSTRA de {len(df_cidades_amostra_ex8)} cidades de clientes (Ex8)...\")\n",
    "    \n",
    "    # Reutilizar country_name_map_airvisual do Ex4\n",
    "    country_name_map_airvisual_ex8 = country_name_map_airvisual \n",
    "    \n",
    "    city_env_data = []\n",
    "    for _, row in df_cidades_amostra_ex8.iterrows():\n",
    "        cidade = row['city']\n",
    "        distrito = row['district']\n",
    "        pais_pagila = row['country_pagila']\n",
    "        pais_api_aqi = country_name_map_airvisual_ex8.get(pais_pagila, pais_pagila)\n",
    "\n",
    "        temp = buscar_clima(cidade)\n",
    "        aqi_val = None\n",
    "        if AIRVISUAL_API_KEY:\n",
    "            aqi_val = buscar_aqi_cidade(cidade, distrito, pais_api_aqi)\n",
    "            if aqi_val is None and (distrito.lower() == cidade.lower() or len(distrito.split()) > 2 or distrito in ['N/A', '']):\n",
    "                 aqi_val = buscar_aqi_cidade(cidade, cidade, pais_api_aqi)\n",
    "        \n",
    "        city_env_data.append({\n",
    "            'city': cidade, 'district': distrito, 'country_pagila': pais_pagila, # Chaves para merge\n",
    "            'temperatura': temp, 'aqi': aqi_val\n",
    "        })\n",
    "    \n",
    "    df_city_env_ex8 = pd.DataFrame(city_env_data)\n",
    "    df_city_env_ex8['temperatura'] = pd.to_numeric(df_city_env_ex8['temperatura'], errors='coerce')\n",
    "    df_city_env_ex8['aqi'] = pd.to_numeric(df_city_env_ex8['aqi'], errors='coerce')\n",
    "\n",
    "    # Merge dos dados ambientais (da amostra de cidades) de volta ao perfil do cliente\n",
    "    df_perfil_cliente_enriquecido_ex8 = pd.merge(\n",
    "        df_perfil_cliente_base_ex8,\n",
    "        df_city_env_ex8,\n",
    "        on=['city', 'district', 'country_pagila'],\n",
    "        how='inner' # 'inner' para pegar apenas clientes das cidades amostradas com dados ambientais\n",
    "    )\n",
    "    \n",
    "    if not df_perfil_cliente_enriquecido_ex8.empty:\n",
    "        print(\"\\nPerfil de Clima por Cliente (amostra de clientes em cidades amostradas):\")\n",
    "        cols_perfil = ['customer_id', 'first_name', 'city', 'temperatura', 'aqi', 'total_alugueis', 'gasto_total']\n",
    "        print(tabulate(df_perfil_cliente_enriquecido_ex8[cols_perfil].head(), headers=\"keys\", tablefmt=\"psql\"))\n",
    "\n",
    "        # 2. Agrupe os perfis por faixa etária (simulada) e avalie padrões.\n",
    "        np.random.seed(42) \n",
    "        faixas_etarias_simuladas = ['18-29', '30-45', '46-59', '60+']\n",
    "        df_perfil_cliente_enriquecido_ex8.loc[:, 'faixa_etaria_simulada'] = np.random.choice(\n",
    "            faixas_etarias_simuladas, size=len(df_perfil_cliente_enriquecido_ex8), p=[0.3, 0.35, 0.25, 0.1]\n",
    "        )\n",
    "\n",
    "        print(\"\\nAnálise de padrões por Faixa Etária Simulada (amostra):\")\n",
    "        \n",
    "        # Gasto total médio por faixa etária\n",
    "        gasto_por_faixa = df_perfil_cliente_enriquecido_ex8.groupby('faixa_etaria_simulada')['gasto_total'].mean().sort_values(ascending=False)\n",
    "        print(\"\\nGasto Total Médio por Faixa Etária Simulada:\")\n",
    "        print(tabulate(pd.DataFrame(gasto_por_faixa), headers=['Faixa Etária', 'Gasto Médio'], tablefmt=\"psql\"))\n",
    "\n",
    "        if 'aqi' in df_perfil_cliente_enriquecido_ex8.columns and not df_perfil_cliente_enriquecido_ex8['aqi'].isnull().all():\n",
    "            df_perfil_cliente_enriquecido_ex8.loc[:, 'qualidade_ar'] = pd.cut(\n",
    "                df_perfil_cliente_enriquecido_ex8['aqi'], bins=[0, 50, 100, 150, np.inf],\n",
    "                labels=['Boa (0-50)', 'Moderada (51-100)', 'Ruim (101-150)', 'Muito Ruim (>150)'], right=True, include_lowest=True\n",
    "            )\n",
    "            gasto_faixa_aqi = df_perfil_cliente_enriquecido_ex8.groupby(['faixa_etaria_simulada', 'qualidade_ar'], observed=False)['gasto_total'].mean().unstack()\n",
    "            print(\"\\nGasto Total Médio por Faixa Etária e Qualidade do Ar (AQI):\")\n",
    "            print(tabulate(gasto_faixa_aqi.fillna(0), headers=\"keys\", tablefmt=\"psql\"))\n",
    "        else:\n",
    "            print(\"\\nDados de AQI não disponíveis ou insuficientes para análise por qualidade do ar.\")\n",
    "\n",
    "        print(\"\\nObjetivo (Exercício 8): Conectar comportamento de consumo e ambiente (exemplificado).\")\n",
    "        print(\"Análise mais profunda requereria dados reais de faixa etária e um conjunto de dados ambientais mais completo.\")\n",
    "    else:\n",
    "        print(\"Não há dados de perfil de cliente (após amostragem e merge com dados ambientais) para análise (Ex8).\")\n",
    "else:\n",
    "    print(\"Não foi possível obter dados base de perfil de cliente (Ex8).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed7a505d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Exercício 9: Exportação Inteligente para Excel ---\n",
      "Média geral de receita (gasto total por cliente na amostra para Ex9): $113.00\n",
      "\n",
      "Número de clientes (da amostra) que atendem aos critérios de exportação: 0\n",
      "\n",
      "Nenhum cliente (da amostra) atendeu a todos os critérios para o relatório Excel.\n"
     ]
    }
   ],
   "source": [
    "# Exercício 9 – Exportação Inteligente\n",
    "\n",
    "print(\"\\n--- Exercício 9: Exportação Inteligente para Excel ---\")\n",
    "\n",
    "# Usar df_perfil_cliente_enriquecido_ex8 se disponível e não vazio.\n",
    "# Este DataFrame já contém customer_id, cidade, país, temperatura, aqi, gasto_total para uma amostra.\n",
    "if 'df_perfil_cliente_enriquecido_ex8' in locals() and not df_perfil_cliente_enriquecido_ex8.empty:\n",
    "    df_para_exporte_ex9 = df_perfil_cliente_enriquecido_ex8.copy()\n",
    "    \n",
    "    # Garantir que colunas numéricas são de fato numéricas\n",
    "    df_para_exporte_ex9['temperatura'] = pd.to_numeric(df_para_exporte_ex9['temperatura'], errors='coerce')\n",
    "    df_para_exporte_ex9['aqi'] = pd.to_numeric(df_para_exporte_ex9['aqi'], errors='coerce')\n",
    "    df_para_exporte_ex9['gasto_total'] = pd.to_numeric(df_para_exporte_ex9['gasto_total'], errors='coerce')\n",
    "\n",
    "    # Calcular média geral de receita (gasto total) da amostra disponível\n",
    "    media_geral_receita_ex9 = df_para_exporte_ex9['gasto_total'].mean()\n",
    "    print(f\"Média geral de receita (gasto total por cliente na amostra para Ex9): ${media_geral_receita_ex9:,.2f}\")\n",
    "\n",
    "    # Aplicar filtros:\n",
    "    # 1. Clientes de cidades com temperatura < 15°C\n",
    "    # 2. AQI da cidade acima de 100\n",
    "    # 3. Gasto total individual > média geral (da amostra)\n",
    "    \n",
    "    # Lidar com NaNs antes de filtrar\n",
    "    df_para_exporte_ex9_com_filtros = df_para_exporte_ex9.dropna(subset=['temperatura', 'aqi', 'gasto_total'])\n",
    "\n",
    "    df_filtrado_export_ex9 = df_para_exporte_ex9_com_filtros[\n",
    "        (df_para_exporte_ex9_com_filtros['temperatura'] < 15) &\n",
    "        (df_para_exporte_ex9_com_filtros['aqi'] > 100) &\n",
    "        (df_para_exporte_ex9_com_filtros['gasto_total'] > media_geral_receita_ex9)\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nNúmero de clientes (da amostra) que atendem aos critérios de exportação: {len(df_filtrado_export_ex9)}\")\n",
    "\n",
    "    if not df_filtrado_export_ex9.empty:\n",
    "        df_clientes_aba = df_filtrado_export_ex9[['customer_id', 'first_name', 'last_name', 'city', 'country_pagila', 'gasto_total']].copy()\n",
    "        df_temperaturas_aba = df_filtrado_export_ex9[['customer_id', 'city', 'country_pagila', 'temperatura']].copy()\n",
    "        df_alertas_aba = df_filtrado_export_ex9[['customer_id', 'city', 'country_pagila', 'aqi', 'temperatura', 'gasto_total']].copy()\n",
    "        df_alertas_aba.loc[:, 'alerta_motivo'] = \"Temp<15 & AQI>100 & Gasto>Média\"\n",
    "\n",
    "        excel_filename = \"relatorio_clientes_criticos.xlsx\"\n",
    "        try:\n",
    "            with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:\n",
    "                df_clientes_aba.to_excel(writer, sheet_name='Clientes_Criticos', index=False)\n",
    "                df_temperaturas_aba.to_excel(writer, sheet_name='Condicoes_Temperatura', index=False)\n",
    "                df_alertas_aba.to_excel(writer, sheet_name='Alertas_Ambientais_Consumo', index=False)\n",
    "            print(f\"\\nRelatório '{excel_filename}' gerado com sucesso com {len(df_filtrado_export_ex9)} clientes.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao gerar o arquivo Excel: {e}. Verifique se 'openpyxl' está instalado.\")\n",
    "    else:\n",
    "        print(\"\\nNenhum cliente (da amostra) atendeu a todos os critérios para o relatório Excel.\")\n",
    "        if not AIRVISUAL_API_KEY:\n",
    "            print(\"Lembrete: A coluna AQI pode estar incompleta se a chave AIRVISUAL_KEY não foi configurada, afetando o filtro.\")\n",
    "        if df_para_exporte_ex9.empty or df_para_exporte_ex9_com_filtros.empty :\n",
    "             print(\"O DataFrame base para exportação estava vazio ou ficou vazio após remoção de NaNs nos campos de filtro.\")\n",
    "\n",
    "else:\n",
    "    print(\"DataFrame 'df_perfil_cliente_enriquecido_ex8' não disponível ou vazio. Pulando Exercício 9.\")\n",
    "    print(\"Execute o Exercício 8 para gerar os dados necessários para este relatório.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "098e3b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Exercício 10: Demonstração do Cache Inteligente ---\n",
      "O sistema de cache (CSV) foi implementado e integrado nas funções:\n",
      "  - buscar_clima() (para WeatherAPI)\n",
      "  - buscar_aqi_cidade() (para AirVisual API)\n",
      "  - buscar_dados_pais() (para REST Countries API)\n",
      "Os arquivos de cache são salvos/lidos do diretório 'api_cache'.\n",
      "\n",
      "Testando buscar_clima() com cache:\n",
      "Clima para 'London' (1ª vez - pode ser API call ou cache hit se já executado): 8.1\n",
      "Clima para 'London' (2ª vez - deve ser CACHE HIT): 8.1\n",
      "Clima para 'Tokyo' (1ª vez): 29.2\n",
      "Clima para 'Tokyo' (2ª vez - CACHE HIT): 29.2\n",
      "\n",
      "Testando buscar_aqi_cidade() com cache (requer AIRVISUAL_KEY):\n",
      "AQI para 'Beijing', 'Beijing', 'China' (1ª vez): None\n",
      "AQI para 'Beijing', 'Beijing', 'China' (2ª vez - CACHE HIT): None\n",
      "AQI para 'Paris', 'Ile-de-France', 'France' (1ª vez): None\n",
      "AQI para 'Paris', 'Ile-de-France', 'France' (2ª vez - CACHE HIT): None\n",
      "\n",
      "Testando buscar_dados_pais() com cache:\n",
      "Dados para 'Brazil' (1ª vez): {'name_common': 'Brazil', 'name_official': 'Federative Republic of Brazil', 'population': 212559409, 'region': 'Americas', 'subregion': 'South America'}\n",
      "Dados para 'Brazil' (2ª vez - CACHE HIT): {'name_common': 'Brazil', 'name_official': 'Federative Republic of Brazil', 'population': 212559409, 'region': 'Americas', 'subregion': 'South America'}\n",
      "Dados para 'Germany' (1ª vez): {'name_common': 'Germany', 'name_official': 'Federal Republic of Germany', 'population': 83240525, 'region': 'Europe', 'subregion': 'Western Europe'}\n",
      "Dados para 'Germany' (2ª vez - CACHE HIT): {'name_common': 'Germany', 'name_official': 'Federal Republic of Germany', 'population': 83240525, 'region': 'Europe', 'subregion': 'Western Europe'}\n",
      "\n",
      "--- Fim da Demonstração do Cache ---\n",
      "Ao reexecutar os exercícios anteriores, as chamadas de API para os mesmos parâmetros devem ser servidas pelo cache, tornando a execução mais rápida.\n"
     ]
    }
   ],
   "source": [
    "# Exercício 10 – API Cache Inteligente (Desafio)\n",
    "# A implementação do cache já foi integrada nas funções de busca de API.\n",
    "# Esta célula serve para demonstrar e testar o cache.\n",
    "\n",
    "print(\"\\n--- Exercício 10: Demonstração do Cache Inteligente ---\")\n",
    "print(\"O sistema de cache (CSV) foi implementado e integrado nas funções:\")\n",
    "print(\"  - buscar_clima() (para WeatherAPI)\")\n",
    "print(\"  - buscar_aqi_cidade() (para AirVisual API)\")\n",
    "print(\"  - buscar_dados_pais() (para REST Countries API)\")\n",
    "print(\"Os arquivos de cache são salvos/lidos do diretório 'api_cache'.\")\n",
    "\n",
    "# Demonstração de uso das funções com cache:\n",
    "print(\"\\nTestando buscar_clima() com cache:\")\n",
    "print(f\"Clima para 'London' (1ª vez - pode ser API call ou cache hit se já executado): {buscar_clima('London')}\")\n",
    "print(f\"Clima para 'London' (2ª vez - deve ser CACHE HIT): {buscar_clima('London')}\")\n",
    "print(f\"Clima para 'Tokyo' (1ª vez): {buscar_clima('Tokyo')}\")\n",
    "print(f\"Clima para 'Tokyo' (2ª vez - CACHE HIT): {buscar_clima('Tokyo')}\")\n",
    "\n",
    "if AIRVISUAL_API_KEY:\n",
    "    print(\"\\nTestando buscar_aqi_cidade() com cache (requer AIRVISUAL_KEY):\")\n",
    "    # Use uma cidade/estado/país válidos para teste\n",
    "    print(f\"AQI para 'Beijing', 'Beijing', 'China' (1ª vez): {buscar_aqi_cidade('Beijing', 'Beijing', 'China')}\")\n",
    "    print(f\"AQI para 'Beijing', 'Beijing', 'China' (2ª vez - CACHE HIT): {buscar_aqi_cidade('Beijing', 'Beijing', 'China')}\")\n",
    "    print(f\"AQI para 'Paris', 'Ile-de-France', 'France' (1ª vez): {buscar_aqi_cidade('Paris', 'Ile-de-France', 'France')}\") # Exemplo, pode precisar ajustar estado/país\n",
    "    print(f\"AQI para 'Paris', 'Ile-de-France', 'France' (2ª vez - CACHE HIT): {buscar_aqi_cidade('Paris', 'Ile-de-France', 'France')}\")\n",
    "else:\n",
    "    print(\"\\nTeste de cache AQI PULADO: Chave AIRVISUAL_KEY não configurada no .env.\")\n",
    "\n",
    "print(\"\\nTestando buscar_dados_pais() com cache:\")\n",
    "print(f\"Dados para 'Brazil' (1ª vez): {buscar_dados_pais('Brazil')}\")\n",
    "print(f\"Dados para 'Brazil' (2ª vez - CACHE HIT): {buscar_dados_pais('Brazil')}\")\n",
    "print(f\"Dados para 'Germany' (1ª vez): {buscar_dados_pais('Germany')}\")\n",
    "print(f\"Dados para 'Germany' (2ª vez - CACHE HIT): {buscar_dados_pais('Germany')}\")\n",
    "\n",
    "print(\"\\n--- Fim da Demonstração do Cache ---\")\n",
    "print(\"Ao reexecutar os exercícios anteriores, as chamadas de API para os mesmos parâmetros devem ser servidas pelo cache, tornando a execução mais rápida.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e6efe6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conexão com o PostgreSQL fechada.\n"
     ]
    }
   ],
   "source": [
    "# Fechar Conexão com o Banco (Opcional, no final do notebook)\n",
    "if conn:\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    print(\"\\nConexão com o PostgreSQL fechada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d959",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
